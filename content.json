{"meta":{"title":"Zhumark's Blog","subtitle":"","description":null,"author":"zhumark","url":"http://www.zhumark.cn"},"pages":[{"title":"About me","date":"2017-08-09T11:56:36.000Z","updated":"2018-04-19T07:33:08.180Z","comments":false,"path":"about/index.html","permalink":"http://www.zhumark.cn/about/index.html","excerpt":"","text":"自我介绍什么的还是算了吧，大概也不会有人关心。 以下是我的联系信息，想交流的话通过以下方式即可。 QQ: 1491579705Email: zhumarkwei@qq.comGithub: https://github.com/zhumark"},{"title":"Categories","date":"2017-08-09T12:02:31.000Z","updated":"2017-08-09T12:03:59.023Z","comments":false,"path":"categories/index.html","permalink":"http://www.zhumark.cn/categories/index.html","excerpt":"","text":""},{"title":"All tags","date":"2017-08-09T11:50:52.000Z","updated":"2017-08-09T11:52:09.767Z","comments":false,"path":"tags/index.html","permalink":"http://www.zhumark.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Sharding-JDBC分库分表","slug":"Sharding-JDBC分库分表","date":"2019-03-08T16:24:56.144Z","updated":"2019-03-10T10:16:05.285Z","comments":true,"path":"2019/03/09/Sharding-JDBC分库分表/","link":"","permalink":"http://www.zhumark.cn/2019/03/09/Sharding-JDBC分库分表/","excerpt":"目前比较流行的基于关系型数据库的数据库中间层有 MyCat 和 Sharding-JDBC，网上介绍 MyCat 相关内容的文章比较多而 Sharding-JDBC 的相对较少，特整理了相关信息，简述一下 Sharding-JDBC 分表分库的有关内容。","text":"目前比较流行的基于关系型数据库的数据库中间层有 MyCat 和 Sharding-JDBC，网上介绍 MyCat 相关内容的文章比较多而 Sharding-JDBC 的相对较少，特整理了相关信息，简述一下 Sharding-JDBC 分表分库的有关内容。 Sharding-JDBC简介Sharding-JDBC 是当当网自研的关系型数据库的水平扩展框架，现在已经捐献给 Apache，是 Apache ShardingSphere（一套开源的分布式数据库中间件解决方案组成的生态圈）的一部分。Sharding-JDBC 采用在 JDBC 协议层扩展分库分表，是一个以 jar 形式提供服务的轻量级组件，其核心思路是小而美地完成最核心的事情。Sharding-JDBC 的设计初衷是想提供一个数据库中间层，用于透明的处理分库分表，而无需业务开发人员在业务代码中根据分片键生成 SQL。主要适用场景为水平拆库和拆表，不太适合 OLAP 的场景和事务强一致的要求。 接下来说说分库分表的概念： 分库分表分为水平拆分和垂直拆分。按照业务分库或分表属于垂直拆分。水平拆分是将同样的库或表按照一定的分片规则拆成多个。 分库和分表都可以有效的处理由于数据量大而导致的查询性能下降的问题。分库还可以缓解高并发对数据库带来的压力，但仅分表可以使用本地事务代替分布式事务。因此分库和分表的合理使用是需要根据业务场景来决定的。 案例场景数据库上面介绍了 Sharding-JDBC 的基本情况，再具体的可以在官网手册中了解。接下来介绍案例场景，本案例创建了2个数据库 database0 和 database1，并且每个数据库都有2个数据表 goods_0 和 goods_1，如下图所示。左边蓝色代表 database0 中的表，右边橘色代表 database1 中的表，上边绿色 goods 表示虚拟表（逻辑表，不存在）。 分库本案例根据 goods_id 的大小进行判断，如果 goods_id 大于20则使用 database0，否则使用 database1。 分表本案例根据数据库 goods_type 的数值的奇偶进行判断，奇数使用 goods_1 表，偶数使用 goods_0 表。 代码实现本文使用 Spring Boot 2.1.2 , SpringData-JPA，Druid 和 Sharding-JDBC。 项目目录结构 建表SQL首先创建需要用到的数据库和表，创建表和数据库的SQL如下所示。 12345678910111213141516171819202122232425262728293031323334CREATE DATABASE database0;USE database0;DROP TABLE IF EXISTS `goods_0`;CREATE TABLE `goods_0` ( `goods_id` bigint(20) NOT NULL, `goods_name` varchar(100) COLLATE utf8_bin NOT NULL, `goods_type` bigint(20) DEFAULT NULL, PRIMARY KEY (`goods_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;DROP TABLE IF EXISTS `goods_1`;CREATE TABLE `goods_1` ( `goods_id` bigint(20) NOT NULL, `goods_name` varchar(100) COLLATE utf8_bin NOT NULL, `goods_type` bigint(20) DEFAULT NULL, PRIMARY KEY (`goods_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;CREATE DATABASE database1;USE database1;DROP TABLE IF EXISTS `goods_0`;CREATE TABLE `goods_0` ( `goods_id` bigint(20) NOT NULL, `goods_name` varchar(100) COLLATE utf8_bin NOT NULL, `goods_type` bigint(20) DEFAULT NULL, PRIMARY KEY (`goods_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;DROP TABLE IF EXISTS `goods_1`;CREATE TABLE `goods_1` ( `goods_id` bigint(20) NOT NULL, `goods_name` varchar(100) COLLATE utf8_bin NOT NULL, `goods_type` bigint(20) DEFAULT NULL, PRIMARY KEY (`goods_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin; 依赖文件新建项目，加入当当的 sharding-jdbc-core 依赖和 druid 连接池，完整 pom 如下所示。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;cn.zhumark&lt;/groupId&gt; &lt;artifactId&gt;shardingjdbc&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;shardingjdbc&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-core&lt;/artifactId&gt; &lt;version&gt;1.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置信息在配置信息中配置了两个数据库的信息和 JPA 的简单配置。 1234567891011121314151617181920212223# spring configurationspring: jpa: database: mysql hibernate: ddl-auto: none show-sql: true# database01 configurationdatabase0: databaseName: database0 driverClassName: com.mysql.cj.jdbc.Driver password: root url: jdbc:mysql://localhost:3306/database0?useUnicode=true&amp;characterEncoding=utf8&amp;characterSetResults=utf8&amp;serverTimezone=GMT%2B8&amp;useSSL=false username: root# database01 configurationdatabase1: databaseName: database1 driverClassName: com.mysql.cj.jdbc.Driver password: root url: jdbc:mysql://localhost:3306/database1?useUnicode=true&amp;characterEncoding=utf8&amp;characterSetResults=utf8&amp;serverTimezone=GMT%2B8&amp;useSSL=false username: root 启动类启动类使用 @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) 禁用数据库自动配置，使用 @EnableTransactionManagement 开启事务，使用 @EnableConfigurationProperties 注解加入配置实体，启动类完整代码如下所示。 123456789101112131415161718package cn.zhumark.shardingjdbc;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.transaction.annotation.EnableTransactionManagement;@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;)@EnableTransactionManagement(proxyTargetClass = true)@EnableConfigurationPropertiespublic class ShardingjdbcApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ShardingjdbcApplication.class, args); &#125;&#125; 实体类和数据库操作层简单的实体和Repository，只不过在Repository内加入between方法和in方法用于测试，代码如下所示。 1234567891011121314151617181920212223package cn.zhumark.shardingjdbc.entity;import lombok.Data;import javax.persistence.Entity;import javax.persistence.Id;import javax.persistence.Table;/** * @author admin * @date 2019/2/2 */@Entity@Table(name = \"goods\")@Datapublic class Goods &#123; @Id private Long goodsId; private String goodsName; private Long goodsType;&#125; 1234567891011121314151617package cn.zhumark.shardingjdbc.repository;import cn.zhumark.shardingjdbc.entity.Goods;import org.springframework.data.jpa.repository.JpaRepository;import java.util.List;/** * @author admin * @date 2019/2/2 */public interface GoodsRepository extends JpaRepository&lt;Goods, Long&gt; &#123; List&lt;Goods&gt; findAllByGoodsIdBetween(Long goodsId1,Long goodsId2); List&lt;Goods&gt; findAllByGoodsIdIn(List&lt;Long&gt; goodsIds);&#125; 数据库配置本文使用了两个实体来接收数据库信息，并且创建数据源。两个数据库配置类代码如下所示。 1234567891011121314151617181920212223242526272829303132package cn.zhumark.shardingjdbc.config;import com.alibaba.druid.pool.DruidDataSource;import lombok.Data;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import javax.sql.DataSource;/** * @author admin * @date 2019/2/2 */@Data@ConfigurationProperties(prefix = \"database0\")@Componentpublic class Database0Config &#123; private String url; private String username; private String password; private String driverClassName; private String databaseName; public DataSource createDataSource() &#123; DruidDataSource result = new DruidDataSource(); result.setDriverClassName(getDriverClassName()); result.setUrl(getUrl()); result.setUsername(getUsername()); result.setPassword(getPassword()); return result; &#125;&#125; 1234567891011121314151617181920212223242526272829303132package cn.zhumark.shardingjdbc.config;import com.alibaba.druid.pool.DruidDataSource;import lombok.Data;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import javax.sql.DataSource;/** * @author admin * @date 2019/2/2 */@Data@ConfigurationProperties(prefix = \"database1\")@Componentpublic class Database1Config &#123; private String url; private String username; private String password; private String driverClassName; private String databaseName; public DataSource createDataSource() &#123; DruidDataSource result = new DruidDataSource(); result.setDriverClassName(getDriverClassName()); result.setUrl(getUrl()); result.setUsername(getUsername()); result.setPassword(getPassword()); return result; &#125;&#125; 接下来新建 DataSourceConfig 用于创建数据源和使用分库分表策略，其中分库分表策略会调用分库算法类和分表算法类，DataSourceConfig 类代码如下所示。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package cn.zhumark.shardingjdbc.config;import cn.zhumark.shardingjdbc.algorithm.DatabaseShardingAlgorithm;import cn.zhumark.shardingjdbc.algorithm.TableShardingAlgorithm;import com.dangdang.ddframe.rdb.sharding.api.ShardingDataSourceFactory;import com.dangdang.ddframe.rdb.sharding.api.rule.DataSourceRule;import com.dangdang.ddframe.rdb.sharding.api.rule.ShardingRule;import com.dangdang.ddframe.rdb.sharding.api.rule.TableRule;import com.dangdang.ddframe.rdb.sharding.api.strategy.database.DatabaseShardingStrategy;import com.dangdang.ddframe.rdb.sharding.api.strategy.table.TableShardingStrategy;import com.dangdang.ddframe.rdb.sharding.keygen.DefaultKeyGenerator;import com.dangdang.ddframe.rdb.sharding.keygen.KeyGenerator;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.sql.DataSource;import java.sql.SQLException;import java.util.Arrays;import java.util.HashMap;import java.util.Map;/** * @author admin * @date 2019/2/2 */@Configurationpublic class DataSourceConfig &#123; @Autowired private Database0Config database0Config; @Autowired private Database1Config database1Config; @Autowired private DatabaseShardingAlgorithm databaseShardingAlgorithm; @Autowired private TableShardingAlgorithm tableShardingAlgorithm; @Bean public DataSource getDataSource() throws SQLException &#123; return buildDataSource(); &#125; private DataSource buildDataSource() throws SQLException &#123; //分库设置 Map&lt;String, DataSource&gt; dataSourceMap = new HashMap&lt;&gt;(2); //添加两个数据库database0和database1 dataSourceMap.put(database0Config.getDatabaseName(), database0Config.createDataSource()); dataSourceMap.put(database1Config.getDatabaseName(), database1Config.createDataSource()); //设置默认数据库 DataSourceRule dataSourceRule = new DataSourceRule(dataSourceMap, database0Config.getDatabaseName()); //分表设置，大致思想就是将查询虚拟表Goods根据一定规则映射到真实表中去 TableRule orderTableRule = TableRule.builder(\"goods\") .actualTables(Arrays.asList(\"goods_0\", \"goods_1\")) .dataSourceRule(dataSourceRule) .build(); //分库分表策略 ShardingRule shardingRule = ShardingRule.builder() .dataSourceRule(dataSourceRule) .tableRules(Arrays.asList(orderTableRule)) .databaseShardingStrategy(new DatabaseShardingStrategy(\"goods_id\", databaseShardingAlgorithm)) .tableShardingStrategy(new TableShardingStrategy(\"goods_type\", tableShardingAlgorithm)).build(); DataSource dataSource = ShardingDataSourceFactory.createDataSource(shardingRule); return dataSource; &#125; @Bean public KeyGenerator keyGenerator() &#123; return new DefaultKeyGenerator(); &#125;&#125; 分库分表算法由于这里只是简单的分库分表样例，所以分库类这里实现 SingleKeyDatabaseShardingAlgorithm 类，采用了单分片键数据源分片算法，需要重写三个方法，分别是： doEqualSharding：SQL中==的规则。 doInSharding：SQL中in的规则。 doBetweenSharding：SQL中between的规则。 本文分库规则是基于值大于20则使用 database0，其余使用 database1，所以简单 if 语句就搞定了，分库算法类 DatabaseShardingAlgorithm 代码如下所示。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package cn.zhumark.shardingjdbc.algorithm;import cn.zhumark.shardingjdbc.config.Database0Config;import cn.zhumark.shardingjdbc.config.Database1Config;import com.dangdang.ddframe.rdb.sharding.api.ShardingValue;import com.dangdang.ddframe.rdb.sharding.api.strategy.database.SingleKeyDatabaseShardingAlgorithm;import com.google.common.collect.Range;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.util.Collection;import java.util.LinkedHashSet;/** * @author admin * @date 2019/2/2 */@Componentpublic class DatabaseShardingAlgorithm implements SingleKeyDatabaseShardingAlgorithm&lt;Long&gt; &#123; @Autowired private Database0Config database0Config; @Autowired private Database1Config database1Config; @Override public String doEqualSharding(Collection&lt;String&gt; availableTargetNames, ShardingValue&lt;Long&gt; shardingValue) &#123; Long value = shardingValue.getValue(); if (value &lt;= 20L) &#123; return database0Config.getDatabaseName(); &#125; else &#123; return database1Config.getDatabaseName(); &#125; &#125; @Override public Collection&lt;String&gt; doInSharding(Collection&lt;String&gt; availableTargetNames, ShardingValue&lt;Long&gt; shardingValue) &#123; Collection&lt;String&gt; result = new LinkedHashSet&lt;&gt;(availableTargetNames.size()); for (Long value : shardingValue.getValues()) &#123; if (value &lt;= 20L) &#123; result.add(database0Config.getDatabaseName()); &#125; else &#123; result.add(database1Config.getDatabaseName()); &#125; &#125; return result; &#125; @Override public Collection&lt;String&gt; doBetweenSharding(Collection&lt;String&gt; availableTargetNames, ShardingValue&lt;Long&gt; shardingValue) &#123; Collection&lt;String&gt; result = new LinkedHashSet&lt;&gt;(availableTargetNames.size()); Range&lt;Long&gt; range = shardingValue.getValueRange(); for (Long value = range.lowerEndpoint(); value &lt;= range.upperEndpoint(); value++) &#123; if (value &lt;= 20L) &#123; result.add(database0Config.getDatabaseName()); &#125; else &#123; result.add(database1Config.getDatabaseName()); &#125; &#125; return result; &#125;&#125; 分表和分库类似，无非就是实现的类不一样，实现了 SingleKeyTableShardingAlgorithm 类，策略使用值奇偶分表，分表算法类 TableShardingAlgorithm 如代码清单所示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package cn.zhumark.shardingjdbc.algorithm;import com.dangdang.ddframe.rdb.sharding.api.ShardingValue;import com.dangdang.ddframe.rdb.sharding.api.strategy.table.SingleKeyTableShardingAlgorithm;import com.google.common.collect.Range;import org.springframework.stereotype.Component;import java.util.Collection;import java.util.LinkedHashSet;/** * @author admin * @date 2019/2/2 */@Componentpublic class TableShardingAlgorithm implements SingleKeyTableShardingAlgorithm&lt;Long&gt; &#123; @Override public String doEqualSharding(final Collection&lt;String&gt; tableNames, final ShardingValue&lt;Long&gt; shardingValue) &#123; for (String each : tableNames) &#123; if (each.endsWith(shardingValue.getValue() % 2 + \"\")) &#123; return each; &#125; &#125; throw new IllegalArgumentException(); &#125; @Override public Collection&lt;String&gt; doInSharding(final Collection&lt;String&gt; tableNames, final ShardingValue&lt;Long&gt; shardingValue) &#123; Collection&lt;String&gt; result = new LinkedHashSet&lt;&gt;(tableNames.size()); for (Long value : shardingValue.getValues()) &#123; for (String tableName : tableNames) &#123; if (tableName.endsWith(value % 2 + \"\")) &#123; result.add(tableName); &#125; &#125; &#125; return result; &#125; @Override public Collection&lt;String&gt; doBetweenSharding(final Collection&lt;String&gt; tableNames, final ShardingValue&lt;Long&gt; shardingValue) &#123; Collection&lt;String&gt; result = new LinkedHashSet&lt;&gt;(tableNames.size()); Range&lt;Long&gt; range = shardingValue.getValueRange(); for (Long i = range.lowerEndpoint(); i &lt;= range.upperEndpoint(); i++) &#123; for (String each : tableNames) &#123; if (each.endsWith(i % 2 + \"\")) &#123; result.add(each); &#125; &#125; &#125; return result; &#125;&#125; 测试Controller接下来创建一个Controller进行测试，保存方法使用了插入40条数据，根据我们的规则，会每个库插入20条，同时还创建了三个查询方法，分别是查询全部，between查询，in查询，还有删除全部方法。Controller类代码如下所示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package cn.zhumark.shardingjdbc.controller;import cn.zhumark.shardingjdbc.entity.Goods;import cn.zhumark.shardingjdbc.repository.GoodsRepository;import com.dangdang.ddframe.rdb.sharding.keygen.KeyGenerator;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import java.util.ArrayList;import java.util.List;/** * @author admin * @date 2019/2/2 */@RestControllerpublic class GoodsController &#123; @Autowired private KeyGenerator keyGenerator; @Autowired private GoodsRepository goodsRepository; @GetMapping(\"save\") public String save() &#123; for (int i = 1; i &lt;= 40; i++) &#123; Goods goods = new Goods(); goods.setGoodsId((long) i); goods.setGoodsName(\"shangpin\" + i); goods.setGoodsType((long) (i + 1)); goodsRepository.save(goods); &#125; return \"success\"; &#125; @GetMapping(\"select\") public String select() &#123; return goodsRepository.findAll().toString(); &#125; @GetMapping(\"delete\") public void delete() &#123; goodsRepository.deleteAll(); &#125; @GetMapping(\"query1\") public Object query1() &#123; return goodsRepository.findAllByGoodsIdBetween(10L, 30L); &#125; @GetMapping(\"query2\") public Object query2() &#123; List&lt;Long&gt; goodsIds = new ArrayList&lt;&gt;(); goodsIds.add(10L); goodsIds.add(15L); goodsIds.add(20L); goodsIds.add(25L); return goodsRepository.findAllByGoodsIdIn(goodsIds); &#125;&#125; 应用测试启动应用，在浏览器或HTTP请求工具访问http://localhost:8080/save，返回success即为正常。 访问http://localhost:8080/select，可以看到数据数组证明插入数据没问题。 然后查看一下数据库 database0 和 database1，每个表都有十条数据，有即为正常。 从上面测试的结果中能够看出分库分表已经按照我们的策略来进行插入，至于其他几个测试这里就不做介绍了，无论是查询和删除都是可以成功的。 以上就是关于 Sharding-JDBC 分库分表的全部内容，刚开始可能用起来不是很习惯，但对于大数据的分库分表这才只是个开始。","categories":[{"name":"SQL","slug":"SQL","permalink":"http://www.zhumark.cn/categories/SQL/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://www.zhumark.cn/tags/SQL/"},{"name":"分表分库","slug":"分表分库","permalink":"http://www.zhumark.cn/tags/分表分库/"}]},{"title":"HTTP代理浅谈","slug":"http代理浅谈","date":"2019-03-08T16:24:56.144Z","updated":"2019-03-10T10:14:42.259Z","comments":true,"path":"2019/03/09/http代理浅谈/","link":"","permalink":"http://www.zhumark.cn/2019/03/09/http代理浅谈/","excerpt":"Web代理(proxy)服务器是网络的中间实体。代理位于客户端和服务器之间，扮演“中间人”的角色，在各端点之间来回传送HTTP报文。 上面这段话来自《HTTP权威指南》，介绍了代理的定义并说明了其作用。现代网络系统中，Web代理无处不在，足可见其重要性。下文将介绍HTTP常见代理的相关知识和概念，包括正向代理，反向代理和透明代理，希望读者能有所收获。","text":"Web代理(proxy)服务器是网络的中间实体。代理位于客户端和服务器之间，扮演“中间人”的角色，在各端点之间来回传送HTTP报文。 上面这段话来自《HTTP权威指南》，介绍了代理的定义并说明了其作用。现代网络系统中，Web代理无处不在，足可见其重要性。下文将介绍HTTP常见代理的相关知识和概念，包括正向代理，反向代理和透明代理，希望读者能有所收获。 一、正向代理（Forward Proxy）一般情况下，如果没有特别说明，代理技术默认说的是正向代理技术。关于正向代理的概念如下： 正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。 HTTP代理存在两种形式，相关介绍如下： 第一种是 RFC 7230 - HTTP/1.1: Message Syntax and Routing（即修订后的 RFC 2616，HTTP/1.1 协议的第一部分）描述的普通代理。这种代理扮演的是「中间人」角色，对于连接到它的客户端来说，它是服务端；对于要连接的服务端来说，它是客户端。它就负责在两端之间来回传送 HTTP 报文。 第二种是 Tunneling TCP based protocols through Web proxy servers（通过 Web 代理服务器用隧道方式传输基于 TCP 的协议）描述的隧道代理。它通过 HTTP 协议正文部分（Body）完成通讯，以 HTTP 的方式实现任意基于 TCP 的应用层协议代理。这种代理使用 HTTP 的 CONNECT 方法建立连接，但 CONNECT 最开始并不是 RFC 2616 - HTTP/1.1 的一部分，直到 2014 年发布的 HTTP/1.1 修订版中，才增加了对 CONNECT 及隧道代理的描述，详见 RFC 7231 - HTTP/1.1: Semantics and Content。实际上这种代理早就被广泛实现。 本文描述的第一种代理，对应《HTTP 权威指南》一书中第六章「代理」；第二种代理，对应第八章「集成点：网关、隧道及中继」中的 8.5 小节「隧道」。 普通代理第一种 Web 代理原理如下： HTTP 客户端向代理发送请求报文，代理服务器需要正确地处理请求和连接（例如正确处理 Connection: keep-alive），同时向服务器发送请求，并将收到的响应转发给客户端。 《HTTP权威指南》如此描述上述行为： 这种方式的代理通常都是依靠修改HTTP请求头部实现，通过x-Forwarded-IP这样的自定义头部告诉服务端真正的客户端 IP，但服务器无法验证这个自定义头部真的是由代理添加，还是客户端修改了请求头，所以这个字段通常只有参考意义。 X-Forwarded-For 是 Squid 缓存代理服务软件引入的，目前已经在规范化在 RFC 7239 文档。 X-Forwarded-For 头部格式也比较简单，比如某个服务器接受到请求的对应头部可能是： 1X-Forwarded-For: client, proxy1, proxy2 对应的值有多个字段，每个字段代表中间的一个节点，它们之间由逗号和空格隔开，从左到右距离当前节点越来越近。最终客户端或者服务器端接受的请求， X-Forwarded-For 是没有最邻近节点的 ip 地址的，而这个地址可以通过 remote address 获取。 每个代理服务器会在 X-Forwarded-For 头部填上前一个节点的 ip 地址，这个地址可以通过 TCP 请求的 remote address 获取。为什么每个代理服务器不填写自己的 ip 地址呢？有两个原因，如果由代理服务器填写自己的 ip 地址，那么代理可以很简单地伪造这个地址，而上一个节点的 remote address 是根据 TCP 连接获取的（如果不建立正确的 TCP 连接是无法进行 HTTP 通信的）；另外一个原因是如果由当前节点填写 X-Forwarded-For ，那么很多情况客户端无法判断自己是否会通过代理的。 以上介绍的内容是第一种正向代理的实现原理，接下来就可用任意支持网络编程的语言实现，以加深理解。这里我选择使用 golang 实现，其他语言类似。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package mainimport ( \"fmt\" \"io\" \"net\" \"net/http\" \"strings\")type Pxy struct&#123;&#125;func (p *Pxy) ServeHTTP(rw http.ResponseWriter, req *http.Request) &#123; fmt.Printf(\"Received request %s %s %s\\n\", req.Method, req.Host, req.RemoteAddr) transport := http.DefaultTransport // step 1 outReq := new(http.Request) *outReq = *req // this only does shallow copies of maps if clientIP, _, err := net.SplitHostPort(req.RemoteAddr); err == nil &#123; if prior, ok := outReq.Header[\"X-Forwarded-For\"]; ok &#123; clientIP = strings.Join(prior, \", \") + \", \" + clientIP &#125; outReq.Header.Set(\"X-Forwarded-For\", clientIP) &#125; // step 2 res, err := transport.RoundTrip(outReq) if err != nil &#123; rw.WriteHeader(http.StatusBadGateway) return &#125; // step 3 for key, value := range res.Header &#123; for _, v := range value &#123; rw.Header().Add(key, v) &#125; &#125; rw.WriteHeader(res.StatusCode) io.Copy(rw, res.Body) res.Body.Close()&#125;func main() &#123; fmt.Println(\"Serve on :8080\") http.Handle(\"/\", &amp;Pxy&#123;&#125;) http.ListenAndServe(\"0.0.0.0:8080\", nil)&#125; 这段代码比较直观，只包含了最核心的代码逻辑，完全按照最上面的代理图例进行组织。一共分成几个步骤： 代理接收到客户端的请求，复制了原来的请求对象，并根据数据配置新请求的各种参数（添加上 X-Forward-For 头部等） 把新请求发送到服务器端，并接收到服务器端返回的响应 代理服务器对响应做一些处理，然后返回给客户端 上面的代码运行之后，会在本地的 8080 端口启动代理服务。修改浏览器的代理为 127.0.0.1:8080 再访问网站，可以验证代理正常工作，也能看到它在终端打印出所有的请求信息。 这个代理目前不支持 HTTPS 协议，因为它只提供了 HTTP 请求的转发功能，并没有处理证书和认证有关的内容。这种代理的本质是中间人，而 HTTPS 网站的证书认证机制是中间人劫持的克星。普通的 HTTPS 服务中，服务端不验证客户端的证书，中间人可以作为客户端与服务端成功完成 TLS 握手；但是中间人没有证书私钥，无论如何也无法伪造成服务端跟客户端建立 TLS 连接。虽然代理可以和真正的服务器建立连接（知道了对方的公钥和证书），但是代理无法代表服务器和客户端建立连接，因为代理服务器无法知道真正服务器的私钥。 隧道代理 HTTP 客户端通过 CONNECT 方法请求隧道代理创建一条到达任意目的服务器和端口的 TCP 连接，并对客户端和服务器之间的后继数据进行盲转发。 下面这张图片同样来自于《HTTP 权威指南》，直观地展示了上述行为： 这种方式的代理使用了 HTTP 的另一种用法——Web 隧道，可以通过 HTTP 应用程序访问使用非 HTTP 协议的应用程序。Web 隧道允许用户通过 HTTP 连接发送非 HTTP 流量，这样就可以捎带上其他协议的数据，达到网络资源复用的目的，减少带宽占用。Web 隧道使用 HTTP 的 CONNECT 方法建立起来，这个方法其实并不是 HTTP/1.1 核心规范的一部分，但确实一种得到广泛应用的扩展。但是需要注意的是，隧道中 HTTP 往返时都是采用明文传输，会被中间人“一览无余”。HTTP 代理承载的 HTTPS 流量，应用数据要等到 TLS 握手成功之后通过 Application Data 协议传输，中间节点无法得知用于流量加密的 master-secret，无法解密数据。而 CONNECT 暴露的域名和端口，对于普通的 HTTPS 请求来说，中间人一样可以拿到（IP 和端口很容易拿到，请求的域名可以通过 DNS Query 或者 TLS Client Hello 中的 Server Name Indication 拿到）。 上图展示了使用 CONNECT 方法建立起来一条到达网关隧道的过程，整个流程如下： 在上图(a)中，客户端发送了一条 CONNECT 请求给隧道网关。客户端的 CONNECT 方法请求隧道网关打开一条TCP连接（这里是到标准 SSL 端口的443的连接）。 在上图(b)和上图(c)中创建 TCP 连接。 一旦建立了 TCP 连接，网关就会发送一条 HTTP 200 Connection Establish响应来通知客户端（上图(d)）。 此时，隧道建立，客户端通过 HTTP 隧道发送的所有数据都会直接转发输出 TCP 连接，服务器发送的所有数据都会通过 HTTP 隧道转发个给客户端。 了解完原理后，再用 golang 实现一个支持 CONNECT 的代理也很简单，核心代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package mainimport ( \"bytes\" \"fmt\" \"io\" \"log\" \"net\" \"net/url\" \"strings\")func main() &#123; log.SetFlags(log.LstdFlags | log.Lshortfile) l, err := net.Listen(\"tcp\", \":8081\") if err != nil &#123; log.Panic(err) &#125; for &#123; client, err := l.Accept() if err != nil &#123; log.Panic(err) &#125; go handleClientRequest(client) &#125;&#125;func handleClientRequest(client net.Conn) &#123; if client == nil &#123; return &#125; defer client.Close() var b [1024]byte n, err := client.Read(b[:]) if err != nil &#123; log.Println(err) return &#125; var method, host, address string fmt.Sscanf(string(b[:bytes.IndexByte(b[:], '\\n')]), \"%s%s\", &amp;method, &amp;host) hostPortURL, err := url.Parse(host) if err != nil &#123; log.Println(err) return &#125; if hostPortURL.Opaque == \"443\" &#123; //https访问 address = hostPortURL.Scheme + \":443\" &#125; else &#123; //http访问 if strings.Index(hostPortURL.Host, \":\") == -1 &#123; //host不带端口， 默认80 address = hostPortURL.Host + \":80\" &#125; else &#123; address = hostPortURL.Host &#125; &#125; //获得了请求的host和port，就开始拨号吧 server, err := net.Dial(\"tcp\", address) if err != nil &#123; log.Println(err) return &#125; if method == \"CONNECT\" &#123; fmt.Fprint(client, \"HTTP/1.1 200 Connection established\\r\\n\\r\\n\") &#125; else &#123; server.Write(b[:n]) &#125; //进行转发 go io.Copy(server, client) io.Copy(client, server)&#125; 以上代码运行后，会在本地 8081端口开启 HTTP 代理服务，这个服务从 CONNECT 请求报文中解析出域名和端口，创建到服务端的 TCP 连接，并和 CONNECT 请求中的 TCP 连接串起来，最后再响应一个 Connection Established 响应。修改浏览器的 HTTP 代理为 127.0.0.1:8081 后再访问 HTTPS 网站，代理可以正常工作。 二、反向代理（Reverse Proxy）上文说到，正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。 而反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，一次客户端并不会感知到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。你看，这就是我们所熟知的 Nginx 扮演的角色。 使用反向代理服务器的主要作用如下： 保护和隐藏原始资源服务器 负载均衡 当反向代理服务器不止一个的时候，我们甚至可以把它们做成集群，当更多的用户访问资源服务器的时候，让不同的代理服务器去应答不同的用户，然后发送不同用户需要的资源。当然反向代理服务器像正向代理服务器一样拥有缓存的作用，它可以缓存原始资源服务器的资源，而不是每次都要向原始资源服务器请求数据，特别是一些静态的数据，比如图片和文件。如果这些反向代理服务器能够做到和用户来自同一个网络，那么用户访问反向代理服务器，就会得到很高质量的速度。这正是 CDN 技术的核心。现在我们不谈 CDN，主要聊聊反向代理。 编写反向代理服务器，用 golang 来实现的话，Golang 给我们提供了编写代理的框架：httputil.ReverseProxy。我们可以用非常简短的代码来实现自己的代理，并且内部的细节问题都已经被很好地处理了。 这部分我们会实现一个简单的反向代理，它能够对请求实现负载均衡，随机地把请求发送给某些配置好的后端服务器。使用 httputil.ReverseProxy 编写反向代理最重要的就是实现自己的 Director 对象，这是 GoDoc 对它的介绍： Director must be a function which modifies the request into a new request to be sent using Transport.Its response is then copied back to the original client unmodified.Director must not access the provided Request after returning. 简单来说，Director 是一个函数，它接受一个请求作为参数，然后对其进行修改。修改后的请求会实际发送给服务器端，我们实现自己的Director函数，修改请求的 Scheme 和 Host ，就能实现负载均衡的效果。 123456789101112131415161718192021222324252627282930313233package mainimport ( \"log\" \"math/rand\" \"net/http\" \"net/http/httputil\" \"net/url\")func NewMultipleHostsReverseProxy(targets []*url.URL) *httputil.ReverseProxy &#123; director := func(req *http.Request) &#123; target := targets[rand.Int()%len(targets)] req.URL.Scheme = target.Scheme req.URL.Host = target.Host req.URL.Path = target.Path &#125; return &amp;httputil.ReverseProxy&#123;Director: director&#125;&#125;func main() &#123; proxy := NewMultipleHostsReverseProxy([]*url.URL&#123; &#123; Scheme: \"http\", Host: \"localhost:80\", &#125;, &#123; Scheme: \"http\", Host: \"localhost:8080\", &#125;, &#125;) log.Fatal(http.ListenAndServe(\":9090\", proxy))&#125; 这段代码运行后，会在本地 9090端口开启 HTTP 代理服务，这个服务会随机的将请求交给本地 80端口和8080端口的服务去执行，在浏览器中直接访问 localhost:9090，多刷新几次就能看到两个真正的服务器提供的资源和页面了。以上只是一个简单的演示和试验，没有错误处理，没有负载均衡算法，没有动态管理后端服务器等等，但却是反向代理的实质和核心。 三、透明代理（Transparent proxy）如果把正向代理、反向代理和透明代理按照人类血缘关系来划分的话。那么正向代理和透明代理是很明显堂亲关系，而正向代理和反向代理就是表亲关系了 。 透明代理的意思是客户端根本不需要知道有代理服务器的存在，它改编你的request fields（报文），并会传送真实 IP。注意，加密的透明代理则是属于匿名代理，意思是不用设置使用代理了。透明代理实践的例子就是时下很多公司使用的行为管理软件。 透明代理技术中的透明是指客户端感觉不到代理的存在，不需要在浏览器中设置任何代理，客户只需要设置缺省网关，客户的访问外部网络的数据包被发送到缺省网关，而这时缺省网关运行有一个代理服务器，数据实际上被被重定向到代理服务器的代理端口（如8080），即由本地代理服务器向外请求所需数据然后拷贝给客户端。理论上透明代理可以对任何协议通用。 但是在这种情况下客户端必须正确设置 DNS 服务器。因为现在浏览器不设置任何代理。则 DNS 查询必须由 browser 来解析，也就是要由客户端必须在 TCP/IP 中设置的正确的DNS服务器，其完成 dns 解析。 以上是关于我对 HTTP 代理的一点浅薄认识，&lt;完结&gt;。 参考文章链接： HTTP 代理原理及实现（一） HTTP代理原理和实现 图解正向代理、反向代理、透明代理","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://www.zhumark.cn/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://www.zhumark.cn/tags/HTTP/"},{"name":"代理","slug":"代理","permalink":"http://www.zhumark.cn/tags/代理/"}]},{"title":"使用Google服务学习机器学习","slug":"使用Google服务跑机器学习","date":"2018-04-18T16:14:01.278Z","updated":"2019-03-10T10:19:02.422Z","comments":true,"path":"2018/04/19/使用Google服务跑机器学习/","link":"","permalink":"http://www.zhumark.cn/2018/04/19/使用Google服务跑机器学习/","excerpt":"机器学习项目运行时间比较长，跑起来非常耗费电脑资源，使用CPU基本是龟速前进。比较好的方法是使用GPU进行加速，然而GPU服务器，无论按小时计费还是按秒计费都非常贵，毕竟资源有限。最近发现，Google拥有一项免费云端机器学习服务，使用的GPU为Tesla K80，效果还是很不错的。","text":"机器学习项目运行时间比较长，跑起来非常耗费电脑资源，使用CPU基本是龟速前进。比较好的方法是使用GPU进行加速，然而GPU服务器，无论按小时计费还是按秒计费都非常贵，毕竟资源有限。最近发现，Google拥有一项免费云端机器学习服务，使用的GPU为Tesla K80，效果还是很不错的。 这项服务就是Google Colab，全名Colaboratory，类似于一个远端的jupyter notebook。你可以用它来提高Python技能，也可以用Keras、TensorFlow、PyTorch、OpenCV等等流行的深度学习库来练练手，开发深度学习应用。 准备工作必须拥有的东西 梯子，保证能访问“外网” Google账号，使用Google Drive存储文件和数据。 在Google Drive上创建文件夹Colab用的数据都存储在Google Drive云端硬盘上，所以，我们需要先指定要在Google Drive上用的文件夹。 比如说，可以在Google Drive上创建一个“app”文件夹，或者其他什么名字，也可以选择Colab笔记本默认的文件夹。 新建Colab笔记本在刚刚创建的app文件夹里点击右键，选择“More”，然后从菜单里选择“Colaboratory”，这样就新建出了一个Colab笔记本。Colab笔记本使用非常方便，和jupyter notebook的使用一模一样。 设置免费GPU在笔记本里点Edit&gt;Notebook settings（编辑&gt;笔记本设置），或者Runtime&gt;Change runtime type（运行时&gt;改变运行时类型），然后在Hardware accelerator（硬件加速器）一栏选择GPU。 然后，就可以使用Google Colab愉快的玩耍了。 运行基本Python代码因为默认已经装好了一些机器学习常用的框架，所以可以直接上手。试着在代码单元格中使用python代码，如使用numpy运算库等，运行结果如你所料。 用Colab运行.py文件Google Drive授权先运行下面这些代码，来安装必要的库、执行授权。 123456789101112!apt-get install -y -qq software-properties-common python-software-properties module-init-tools!add-apt-repository -y ppa:alessandro-strada/ppa 2&gt;&amp;1 &gt; /dev/null!apt-get update -qq 2&gt;&amp;1 &gt; /dev/null!apt-get -y install -qq google-drive-ocamlfuse fusefrom google.colab import authauth.authenticate_user()from oauth2client.client import GoogleCredentialscreds = GoogleCredentials.get_application_default()import getpass!google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125; &lt; /dev/null 2&gt;&amp;1 | grep URLvcode = getpass.getpass()!echo &#123;vcode&#125; | google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125; 看见那个链接之后，点击它，复制验证码并粘贴到文本框里,确认后就可以看到授权成功的信息了。 授权完成后，就可以挂载Google Drive了： 12!mkdir -p drive!google-drive-ocamlfuse drive 每隔一段时间之后，colab给分配的环境会被自动初始化，下次进来得重新挂载google drive，以上代码几乎每次打开都得执行。 Colab 自带了 Tensorflow、Matplotlib、Numpy、Pandas 等深度学习基础库。如果还需要其他依赖，如 Keras，可以新建代码块，输入 123456789101112131415161718# 安装最新版本Keras# https://keras.io/!pip install keras# 指定版本安装!pip install keras==2.0.9# 安装 OpenCV# https://opencv.org/!apt-get -qq install -y libsm6 libxext6 &amp;&amp; pip install -q -U opencv-python# 安装 Pytorch# http://pytorch.org/!pip install -q http://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp27-cp27mu-manylinux1_x86_64.whl torchvision# 安装 XGBoost# https://github.com/dmlc/xgboost!pip install -q xgboost# 安装 7Zip!apt-get -qq install -y libarchive-dev &amp;&amp; pip install -q -U libarchive# 安装 GraphViz 和 PyDot!apt-get -qq install -y graphviz &amp;&amp; pip install -q pydot 将mnist_cnn.py文件上传到位于Google云端硬盘上的应用文件夹： 运行下面的代码，用MNIST数据集训练一个简单的卷积神经网络： 1!python3 drive/app/mnist_cnn.py 从结果中可以看到，每个epoch只需要11秒。 下载泰坦尼克数据集想按照链接下载.csv文件到app文件夹，只需运行： 1!wget https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/Titanic.csv -P drive/app 也可以直接将.csv文件上传到app文件夹。 一些小的代码片段在笔记本的左侧，打开三角形的指示器，在代码段目录下，你可以看到一些Google提供的小脚本，方便你的一些操作。 例如，你可以安装7zip reader 12!apt-get -qq install -y libarchive-dev &amp;&amp; pip install -q -U libarchivimport libarchive 也可以保存数据到Google Drive 1234567891011121314151617181920# Install the PyDrive wrapper &amp; import libraries.# This only needs to be done once in a notebook.!pip install -U -q PyDrivefrom pydrive.auth import GoogleAuthfrom pydrive.drive import GoogleDrivefrom google.colab import authfrom oauth2client.client import GoogleCredentials# Authenticate and create the PyDrive client.# This only needs to be done once in a notebook.auth.authenticate_user()gauth = GoogleAuth()gauth.credentials = GoogleCredentials.get_application_default()drive = GoogleDrive(gauth)# Create &amp; upload a text file.uploaded = drive.CreateFile(&#123;'title': 'Sample file.txt'&#125;)uploaded.SetContentString('Sample upload file content')uploaded.Upload()print('Uploaded file with ID &#123;&#125;'.format(uploaded.get('id'))) 要查看你在Colab里是不是真的在用GPU，可以运行以下代码来交叉检查： 12import tensorflow as tftf.test.gpu_device_name() 要想知道你在使用那块GPU，使用下面的代码即可： 12from tensorflow.python.client import device_libdevice_lib.list_local_devices() 按照输出结果来看，其实Colab只有一个CPU和一块Tesla K80的GPU，但这对我们开始足够了。 查看RAM和CPU信息： 12!cat /proc/meminfo!cat /proc/cpuinfo 在colab环境中，我们挂载Google drive的位置是/content/drive/ 。colab中的notebook和py文件默认都是以/content/ 作为工作目录，如果我们要切换工作路径。需要执行一下命令手动切换工作目录，例如： 1234import ospath = \"/content/drive/path/to/file(s)\"os.chdir(path)os.list(path) 遍历目录 12345# 列出根目录的所有文件# \"q\" 查询条件教程详见：https://developers.google.com/drive/v2/web/search-parametersfile_list = drive.ListFile(&#123;'q': \"'root' in parents and trashed=false\"&#125;).GetList()for file1 in file_list: print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"])) 我们看到的控制台打印结果中，其中的id是我们获取文件的唯一标识。 读取文件内容 123456789101112131415#for .txt filefile = drive.CreateFile(&#123;'id': \"替换成你的 .txt 文件 id\"&#125;) file.GetContentString()#for .csv file#GetContentString()只能打印第一行数据file = drive.CreateFile(&#123;'id': \"替换成你的 .csv 文件 id\"&#125;) #这里的下载操作只是缓存，不会在你的Google Drive 目录下多下载一个文件file.GetContentFile('iris.csv', \"text/csv\") # 直接打印文件内容with open('iris.csv') as f: print f.readlines()# 用 pandas 读取import pandaspd.read_csv('iris.csv', index_col=[0,1], skipinitialspace=True) Colab 会直接以表格的形式输出结果 写文件操作 12345# 创建一个文本文件uploaded = drive.CreateFile(&#123;'title': '示例.txt'&#125;)uploaded.SetContentString('测试内容')uploaded.Upload()print('创建后文件 id 为 &#123;&#125;'.format(uploaded.get('id'))) 下载文件到本地 123with open('example.txt', 'w') as f: f.write('测试内容')files.download('example.txt') 至此，所有的介绍完毕，请开始你的机器学习吧，事不宜迟，赶快动手试试看。至于实战什么的，试着试着就知道咯，欢迎入坑！ 参考文章链接https://zhuanlan.zhihu.com/p/33344222 https://segmentfault.com/a/1190000012731724","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://www.zhumark.cn/categories/Machine-Learning/"}],"tags":[{"name":"Google","slug":"Google","permalink":"http://www.zhumark.cn/tags/Google/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://www.zhumark.cn/tags/Machine-Learning/"}]}]}